# SRE/DevOps Learning Roadmap

## Aplicando Skills da Vaga Conquest One ao RHCSA Practice Labs

Este documento mapeia como aplicar cada tecnologia da vaga SRE/DevOps ao projeto existente.

---

## 1. Docker - ContainerizaÃ§Ã£o

### O que fazer:
- Criar `Dockerfile` para a API Flask
- Criar `Dockerfile` para os VMs de teste (usando containers ao invÃ©s de Vagrant)
- Criar `docker-compose.yml` para orquestraÃ§Ã£o local

### Estrutura proposta:
```
docker/
â”œâ”€â”€ Dockerfile.api          # Flask API container
â”œâ”€â”€ Dockerfile.examnode     # Rocky Linux exam node
â”œâ”€â”€ docker-compose.yml      # Full stack local
â””â”€â”€ docker-compose.dev.yml  # Dev with hot reload
```

### Exemplo Dockerfile.api:
```dockerfile
FROM python:3.12-slim
WORKDIR /app
COPY api/requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
COPY api/ ./api/
COPY static/ ./static/
COPY exam-grader.sh checks/ ./
EXPOSE 8080
CMD ["python", "api/app.py"]
```

### Aprendizado:
- Multi-stage builds
- Layer caching
- Security best practices (non-root user)
- Health checks

---

## 2. Kubernetes - OrquestraÃ§Ã£o

### O que fazer:
- Criar manifests K8s para deploy da aplicaÃ§Ã£o
- Configurar Services, Deployments, ConfigMaps, Secrets
- Implementar probes (liveness/readiness)

### Estrutura proposta:
```
k8s/
â”œâ”€â”€ base/
â”‚   â”œâ”€â”€ deployment.yaml
â”‚   â”œâ”€â”€ service.yaml
â”‚   â”œâ”€â”€ configmap.yaml
â”‚   â””â”€â”€ kustomization.yaml
â”œâ”€â”€ overlays/
â”‚   â”œâ”€â”€ dev/
â”‚   â””â”€â”€ prod/
â””â”€â”€ README.md
```

### Exemplo deployment.yaml:
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: rhcsa-api
spec:
  replicas: 2
  selector:
    matchLabels:
      app: rhcsa-api
  template:
    metadata:
      labels:
        app: rhcsa-api
    spec:
      containers:
      - name: api
        image: rhcsa-practice-labs:latest
        ports:
        - containerPort: 8080
        livenessProbe:
          httpGet:
            path: /api/healthcheck
            port: 8080
        readinessProbe:
          httpGet:
            path: /api/healthcheck
            port: 8080
        resources:
          limits:
            memory: "256Mi"
            cpu: "500m"
```

### Aprendizado:
- Kustomize para ambiente mÃºltiplos
- Resource limits e requests
- Pod disruption budgets
- Network policies

---

## 3. Helm - Gerenciamento de Charts

### O que fazer:
- Criar Helm chart para a aplicaÃ§Ã£o
- Parametrizar configuraÃ§Ãµes
- Versionar releases

### Estrutura proposta:
```
helm/
â””â”€â”€ rhcsa-labs/
    â”œâ”€â”€ Chart.yaml
    â”œâ”€â”€ values.yaml
    â”œâ”€â”€ values-dev.yaml
    â”œâ”€â”€ values-prod.yaml
    â””â”€â”€ templates/
        â”œâ”€â”€ deployment.yaml
        â”œâ”€â”€ service.yaml
        â”œâ”€â”€ configmap.yaml
        â”œâ”€â”€ ingress.yaml
        â””â”€â”€ _helpers.tpl
```

### Exemplo values.yaml:
```yaml
replicaCount: 2
image:
  repository: ghcr.io/your-org/rhcsa-practice-labs
  tag: "latest"
  pullPolicy: IfNotPresent

service:
  type: ClusterIP
  port: 80

ingress:
  enabled: true
  className: nginx
  hosts:
    - host: rhcsa.example.com
      paths:
        - path: /
          pathType: Prefix

resources:
  limits:
    cpu: 500m
    memory: 256Mi
  requests:
    cpu: 100m
    memory: 128Mi
```

### Aprendizado:
- Template functions
- Chart dependencies
- Helm hooks (pre-install, post-upgrade)
- Chart testing

---

## 4. GitHub Actions - CI/CD

### O que fazer:
- Pipeline de build e test
- Build e push de imagem Docker
- Deploy automatizado
- Security scanning

### Estrutura proposta:
```
.github/
â””â”€â”€ workflows/
    â”œâ”€â”€ ci.yml           # Lint, test, build
    â”œâ”€â”€ cd.yml           # Deploy to environments
    â”œâ”€â”€ security.yml     # Vulnerability scanning
    â””â”€â”€ release.yml      # Semantic versioning
```

### Exemplo ci.yml:
```yaml
name: CI Pipeline

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

jobs:
  lint:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Lint Python
        uses: py-actions/flake8@v2
      - name: Lint Shell
        uses: ludeeus/action-shellcheck@master
        with:
          scandir: './checks'

  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.12'
      - name: Install deps
        run: pip install -r api/requirements.txt pytest
      - name: Run tests
        run: pytest tests/

  build:
    needs: [lint, test]
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Build Docker image
        run: docker build -t rhcsa-labs:${{ github.sha }} -f docker/Dockerfile.api .
      - name: Push to GHCR
        if: github.ref == 'refs/heads/main'
        run: |
          echo ${{ secrets.GITHUB_TOKEN }} | docker login ghcr.io -u ${{ github.actor }} --password-stdin
          docker tag rhcsa-labs:${{ github.sha }} ghcr.io/${{ github.repository }}:latest
          docker push ghcr.io/${{ github.repository }}:latest
```

### Aprendizado:
- Matrix builds
- Caching strategies
- Environment secrets
- Reusable workflows
- Branch protection rules

---

## 5. Terraform - Infrastructure as Code

### O que fazer:
- Provisionar infraestrutura GCP
- Criar GKE cluster
- Configurar CloudSQL
- Gerenciar IAM

### Estrutura proposta:
```
terraform/
â”œâ”€â”€ environments/
â”‚   â”œâ”€â”€ dev/
â”‚   â”‚   â”œâ”€â”€ main.tf
â”‚   â”‚   â”œâ”€â”€ variables.tf
â”‚   â”‚   â””â”€â”€ terraform.tfvars
â”‚   â””â”€â”€ prod/
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ gke/
â”‚   â”œâ”€â”€ cloudsql/
â”‚   â”œâ”€â”€ iam/
â”‚   â””â”€â”€ networking/
â””â”€â”€ README.md
```

### Exemplo modules/gke/main.tf:
```hcl
resource "google_container_cluster" "primary" {
  name     = var.cluster_name
  location = var.region

  # Usar node pool separado
  remove_default_node_pool = true
  initial_node_count       = 1

  network    = var.network
  subnetwork = var.subnetwork

  workload_identity_config {
    workload_pool = "${var.project_id}.svc.id.goog"
  }
}

resource "google_container_node_pool" "primary_nodes" {
  name       = "${var.cluster_name}-node-pool"
  location   = var.region
  cluster    = google_container_cluster.primary.name
  node_count = var.node_count

  node_config {
    preemptible  = var.preemptible
    machine_type = var.machine_type

    oauth_scopes = [
      "https://www.googleapis.com/auth/cloud-platform"
    ]
  }
}
```

### Aprendizado:
- State management (remote backend)
- Workspaces
- Module composition
- Terraform Cloud/Enterprise
- Import existing resources

---

## 6. GCP - Cloud Provider

### ServiÃ§os a implementar:

#### GKE (Google Kubernetes Engine)
- Cluster para rodar a aplicaÃ§Ã£o
- Node pools com autoscaling
- Workload Identity

#### IAM
- Service accounts para aplicaÃ§Ã£o
- Least privilege principle
- Workload Identity Federation

#### CloudSQL
- Substituir SQLite por PostgreSQL managed
- Private IP connectivity
- Automated backups

#### Cloud Monitoring
- Custom metrics da aplicaÃ§Ã£o
- Alertas de SLO/SLI
- Dashboards

### Estrutura proposta:
```
gcp/
â”œâ”€â”€ cloudsql/
â”‚   â””â”€â”€ migration.sql     # Schema migration
â”œâ”€â”€ monitoring/
â”‚   â”œâ”€â”€ dashboards/
â”‚   â””â”€â”€ alerts/
â””â”€â”€ iam/
    â””â”€â”€ roles.yaml
```

---

## 7. Observabilidade

### O que fazer:
- Instrumentar a API Flask
- Configurar logging estruturado
- Implementar mÃ©tricas customizadas
- Distributed tracing

### Estrutura proposta:
```
observability/
â”œâ”€â”€ prometheus/
â”‚   â””â”€â”€ rules.yaml
â”œâ”€â”€ grafana/
â”‚   â””â”€â”€ dashboards/
â”‚       â””â”€â”€ rhcsa-labs.json
â”œâ”€â”€ elk/
â”‚   â””â”€â”€ logstash.conf
â””â”€â”€ datadog/
    â””â”€â”€ monitors.yaml
```

### InstrumentaÃ§Ã£o Flask:
```python
# api/metrics.py
from prometheus_client import Counter, Histogram, generate_latest
import time

REQUEST_COUNT = Counter(
    'rhcsa_request_total',
    'Total requests',
    ['method', 'endpoint', 'status']
)

REQUEST_LATENCY = Histogram(
    'rhcsa_request_latency_seconds',
    'Request latency',
    ['method', 'endpoint']
)

TASK_GRADING = Histogram(
    'rhcsa_task_grading_seconds',
    'Task grading duration',
    ['task_id']
)

TASK_RESULTS = Counter(
    'rhcsa_task_results_total',
    'Task grading results',
    ['task_id', 'result']  # passed/failed
)
```

### Logging estruturado:
```python
import structlog

logger = structlog.get_logger()

@app.route('/api/grade-task/<task_id>')
def grade_task(task_id):
    logger.info(
        "grading_task",
        task_id=task_id,
        user_agent=request.headers.get('User-Agent')
    )
```

### Aprendizado:
- RED method (Rate, Errors, Duration)
- USE method (Utilization, Saturation, Errors)
- SLI/SLO/SLA definition
- Alert fatigue prevention

---

## 8. Git - Boas PrÃ¡ticas

### O que fazer:
- Implementar Conventional Commits
- Branch protection rules
- Git hooks (pre-commit)
- Semantic versioning

### Estrutura proposta:
```
.github/
â”œâ”€â”€ CODEOWNERS
â”œâ”€â”€ pull_request_template.md
â””â”€â”€ ISSUE_TEMPLATE/
    â”œâ”€â”€ bug_report.md
    â””â”€â”€ feature_request.md

.husky/
â””â”€â”€ pre-commit

.commitlintrc.json
```

### Conventional Commits:
```
feat(api): add task filtering by category
fix(grader): handle timeout in SSH connection
docs(readme): add deployment instructions
chore(deps): update Flask to 3.0.0
ci(actions): add security scanning workflow
```

---

## 9. Nexus - Gerenciamento de Artefatos

### O que fazer:
- Configurar Nexus como Docker registry
- Proxy para PyPI
- Hospedar Helm charts

### Estrutura proposta:
```
nexus/
â”œâ”€â”€ docker-compose.yml    # Local Nexus instance
â”œâ”€â”€ configure.sh          # Repository setup script
â””â”€â”€ README.md
```

### Aprendizado:
- Repository types (hosted, proxy, group)
- Cleanup policies
- Security scanning integration
- High availability setup

---

## 10. Python/Shell Automation

### O que fazer:
- Scripts de deploy
- Automation de tasks repetitivas
- CLI tools

### Estrutura proposta:
```
scripts/
â”œâ”€â”€ deploy.py             # Deployment automation
â”œâ”€â”€ cleanup.py            # Resource cleanup
â”œâ”€â”€ rotate-secrets.sh     # Secret rotation
â””â”€â”€ healthcheck.sh        # System health checks
```

### Exemplo deploy.py:
```python
#!/usr/bin/env python3
"""Deployment automation script"""
import click
import subprocess
from pathlib import Path

@click.group()
def cli():
    """RHCSA Labs deployment CLI"""
    pass

@cli.command()
@click.option('--env', type=click.Choice(['dev', 'staging', 'prod']))
@click.option('--dry-run', is_flag=True)
def deploy(env, dry_run):
    """Deploy to specified environment"""
    click.echo(f"Deploying to {env}...")
    # Implementation

@cli.command()
def rollback():
    """Rollback to previous version"""
    # Implementation

if __name__ == '__main__':
    cli()
```

---

## 11. AIOps / AI para Observabilidade (Diferencial)

### O que fazer:
- Anomaly detection em mÃ©tricas
- Log analysis com ML
- Predictive alerting
- ChatOps com LLM

### Estrutura proposta:
```
aiops/
â”œâ”€â”€ anomaly_detection/
â”‚   â””â”€â”€ detect.py         # Time series anomaly detection
â”œâ”€â”€ log_analysis/
â”‚   â””â”€â”€ classify.py       # Log classification
â””â”€â”€ chatops/
    â””â”€â”€ slack_bot.py      # AI-powered incident response
```

### Exemplo simples de anomaly detection:
```python
import numpy as np
from sklearn.ensemble import IsolationForest

def detect_anomalies(metrics: list[float], threshold: float = 0.1):
    """Detect anomalies in time series metrics"""
    model = IsolationForest(contamination=threshold)
    data = np.array(metrics).reshape(-1, 1)
    predictions = model.fit_predict(data)
    return [i for i, p in enumerate(predictions) if p == -1]
```

---

## Roadmap de ImplementaÃ§Ã£o

### Fase 1 - Foundation (2 semanas)
1. âœ… AnÃ¡lise do projeto atual
2. ðŸ”² DockerizaÃ§Ã£o da aplicaÃ§Ã£o
3. ðŸ”² Testes unitÃ¡rios bÃ¡sicos
4. ðŸ”² GitHub Actions CI bÃ¡sico

### Fase 2 - Kubernetes (2 semanas)
1. ðŸ”² Manifests K8s
2. ðŸ”² Helm chart
3. ðŸ”² Local testing com kind/minikube

### Fase 3 - Cloud (3 semanas)
1. ðŸ”² Terraform modules
2. ðŸ”² GKE cluster
3. ðŸ”² CloudSQL migration
4. ðŸ”² CD pipeline

### Fase 4 - Observability (2 semanas)
1. ðŸ”² Prometheus metrics
2. ðŸ”² Grafana dashboards
3. ðŸ”² Alerting rules
4. ðŸ”² Structured logging

### Fase 5 - Advanced (ongoing)
1. ðŸ”² Nexus setup
2. ðŸ”² AIOps experiments
3. ðŸ”² Chaos engineering
4. ðŸ”² Cost optimization

---

## PrÃ³ximos Passos

Quer que eu comece a implementar alguma dessas fases? Sugiro comeÃ§ar por:

1. **Docker** - Base para todo o resto
2. **GitHub Actions** - CI imediato com cada commit
3. **Observability** - MÃ©tricas na API existente

Cada uma dessas pode ser implementada incrementalmente sem quebrar o projeto atual.
